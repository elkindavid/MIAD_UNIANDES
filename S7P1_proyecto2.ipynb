{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 2 - Clasificación de género de películas\n",
    "\n",
    "El propósito de este proyecto es que puedan poner en práctica, en sus respectivos grupos de trabajo, sus conocimientos sobre técnicas de preprocesamiento, modelos predictivos de NLP, y la disponibilización de modelos. Para su desarrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 2: Clasificación de género de películas\"\n",
    "\n",
    "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 8. Sin embargo, es importante que avancen en la semana 7 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
    "\n",
    "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 8, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/t/2c54d005f76747fe83f77fbf8b3ec232)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos para la predicción de género en películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/moviegenre.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto se usará un conjunto de datos de géneros de películas. Cada observación contiene el título de una película, su año de lanzamiento, la sinopsis o plot de la película (resumen de la trama) y los géneros a los que pertenece (una película puede pertenercer a más de un género). Por ejemplo:\n",
    "- Título: 'How to Be a Serial Killer'\n",
    "- Plot: 'A serial killer decides to teach the secrets of his satisfying career to a video store clerk.'\n",
    "- Generos: 'Comedy', 'Crime', 'Horror'\n",
    "\n",
    "La idea es que usen estos datos para predecir la probabilidad de que una película pertenezca, dada la sinopsis, a cada uno de los géneros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agradecemos al profesor Fabio González, Ph.D. y a su alumno John Arevalo por proporcionar este conjunto de datos. Ver https://arxiv.org/abs/1702.01992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo predicción conjunto de test para envío a Kaggle\n",
    "En esta sección encontrarán el formato en el que deben guardar los resultados de la predicción para que puedan subirlos a la competencia en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import re,string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import RepeatedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "Train = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "Test = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining = Train\n",
    "dataTesting = Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de test\n",
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generos = []\n",
    "\n",
    "for i in dataTraining['genres']:\n",
    "    list_genres = ast.literal_eval(i)\n",
    "    for j in list_genres:\n",
    "        generos.append(j)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(x=generos)    # Count of number of descriptions for each class label\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "pd.DataFrame(generos).value_counts().plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining['plot length']=dataTraining['plot'].apply(lambda x:len(x))   # calculating length of plot for each row\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re,string\n",
    "# import nltk\n",
    "# #nltk.download('stopwords')    # uncomment if stopwords are not downloaded\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import LancasterStemmer\n",
    "\n",
    "# stemmer=LancasterStemmer()\n",
    "# stopwords=stopwords.words('english')\n",
    "\n",
    "# def clean_text(text):\n",
    "#     text=re.sub('-',' ',text.lower())   # replace `word-word` as `word word`\n",
    "#     text = ' '.join([stemmer.stem(word) for word in text.split() if word not in stopwords]) # remove stopwords and stem other words\n",
    "#     text=re.sub(f'[{string.digits}]',' ',text)  # remove digits\n",
    "#     return re.sub(f'[{re.escape(string.punctuation)}]','',text) # remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTraining['cleaned plot']=dataTraining['plot'].apply(clean_text)  # clean text for all rows of description\n",
    "# dataTesting['cleaned plot']=dataTesting['plot'].apply(clean_text)\n",
    "# dataTraining['cleaned plot length']=dataTraining['cleaned plot'].apply(lambda x:len(x))  # calculate length of cleaned text\n",
    "# dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (dataTraining['cleaned plot length']>1500).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove extremely long descriptions: outliers\n",
    "# print('Dataframe size (before removal): ',len(dataTraining))\n",
    "# filt=dataTraining['cleaned plot length']>1500\n",
    "# dataTraining.drop(dataTraining[filt].index,axis=0,inplace=True)     # filter rows having cleaned description length > 2000\n",
    "# print('Dataframe size (after removal): ',len(dataTraining))\n",
    "# print(f'Removed rows: {filt.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataTraining.drop(columns=['title','plot','plot length','cleaned plot length'],axis=1,inplace=True)     # drop unnecessary columns for model\n",
    "# dataTesting.drop(columns=['title','plot'],axis=1,inplace=True)\n",
    "# dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variables predictoras (X)\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=stopwords.words('english')\n",
    "\n",
    "vect = CountVectorizer(max_features=1500, lowercase = False, stop_words=stopwords)\n",
    "X_dtm = vect.fit_transform(dataTraining['plot'])\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importación de librerias\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definiicón de lista con vocabulario de la matriz de documentos\n",
    "# words = list(vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definición de la función que tenga como parámetro texto y devuelva una lista de lemas\n",
    "# def split_into_lemmas(text):\n",
    "#     text = text.lower()\n",
    "#     words = text.split()\n",
    "#     return [wordnet_lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creación de matrices de documentos usando CountVectorizer, usando el parámetro 'split_into_lemmas'\n",
    "# vect_lemas = CountVectorizer(analyzer=split_into_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Desempeño del modelo al lematizar el texto\n",
    "# vect_lemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variable de interés (y)\n",
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test usandola función train_test_split\n",
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grid de hiperparámetros evaluados\n",
    "# # ==============================================================================\n",
    "# param_grid = {'n_estimators'  : [50, 100, 500, 1000],\n",
    "#               'max_features'  : ['auto', 'sqrt', 'log2'],\n",
    "#               'max_depth'     : [None, 1, 3, 5, 10, 20],\n",
    "#               'subsample'     : [0.5, 1],\n",
    "#               'learning_rate' : [0.001, 0.01, 0.1]\n",
    "#              }\n",
    "\n",
    "# # Búsqueda por grid search con validación cruzada\n",
    "# # ==============================================================================\n",
    "# grid = GridSearchCV(\n",
    "#         estimator  = xgb.XGBClassifier(random_state=123),\n",
    "#         param_grid = param_grid,\n",
    "#         scoring    = 'accuracy',\n",
    "#         n_jobs     = multiprocessing.cpu_count() - 1,\n",
    "#         cv         = RepeatedKFold(n_splits=3, n_repeats=1, random_state=123), \n",
    "#         refit      = True,\n",
    "#         verbose    = 0,\n",
    "#         return_train_score = True\n",
    "#        )\n",
    "\n",
    "# grid.fit(X = X_train, y = y_train_genres)\n",
    "\n",
    "# # Resultados\n",
    "# # ==============================================================================\n",
    "# resultados = pd.DataFrame(grid.cv_results_)\n",
    "# resultados.filter(regex = '(param*|mean_t|std_t)') \\\n",
    "#     .drop(columns = 'params') \\\n",
    "#     .sort_values('mean_test_score', ascending = False) \\\n",
    "#     .head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mejores hiperparámetros por validación cruzada\n",
    "# # ==============================================================================\n",
    "# print(\"----------------------------------------\")\n",
    "# print(\"Mejores hiperparámetros encontrados (cv)\")\n",
    "# print(\"----------------------------------------\")\n",
    "# print(grid.best_params_, \":\", grid.best_score_, grid.scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=10,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=42, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=10,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=42, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "              predictor=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_threshold=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=10,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=42, ...))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición y entrenamiento\n",
    "clf = OneVsRestClassifier(xgb.XGBClassifier(n_jobs=-1, n_estimators=100, max_depth=10, random_state=42))\n",
    "clf.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8025316749427879"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción del modelo de clasificación\n",
    "y_pred_genres = clf.predict_proba(X_test)\n",
    "\n",
    "# Impresión del desempeño del modelo\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformación variables predictoras X del conjunto de test\n",
    "X_test_dtm = vect.transform(dataTesting['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_genres = clf.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.052310</td>\n",
       "      <td>0.039072</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.151989</td>\n",
       "      <td>0.026575</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.470647</td>\n",
       "      <td>0.024712</td>\n",
       "      <td>0.037654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.987415</td>\n",
       "      <td>0.013618</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.086193</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.002179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025965</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.004291</td>\n",
       "      <td>0.575535</td>\n",
       "      <td>0.045121</td>\n",
       "      <td>0.307576</td>\n",
       "      <td>0.294935</td>\n",
       "      <td>0.944089</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.153691</td>\n",
       "      <td>0.034821</td>\n",
       "      <td>0.003528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.021729</td>\n",
       "      <td>0.419026</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.680908</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.327308</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.151924</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>0.570237</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025874</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.043484</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.856734</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.144440</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.061414</td>\n",
       "      <td>0.054991</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.845745</td>\n",
       "      <td>0.038545</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.109577</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.148409</td>\n",
       "      <td>0.061959</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.075539</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>0.459454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.026427</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>0.168180</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.260326</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.052310     0.039072     0.000420     0.002565  0.151989  0.026575   \n",
       "4  0.025965     0.005199     0.004291     0.575535  0.045121  0.307576   \n",
       "5  0.001451     0.000202     0.000040     0.000369  0.021729  0.419026   \n",
       "6  0.025874     0.045130     0.000053     0.001681  0.043484  0.051594   \n",
       "7  0.109577     0.030596     0.001107     0.001990  0.148409  0.061959   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.000664  0.470647  0.024712   0.037654  ...   0.009205   0.027514   \n",
       "4       0.294935  0.944089  0.003839   0.002557  ...   0.002849   0.009960   \n",
       "5       0.000074  0.680908  0.000041   0.001767  ...   0.000193   0.327308   \n",
       "6       0.001757  0.856734  0.001092   0.009028  ...   0.000552   0.144440   \n",
       "7       0.000511  0.075539  0.016060   0.459454  ...   0.007466   0.026427   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000017   0.987415  0.013618  0.000280  0.000530    0.086193  0.001020   \n",
       "4  0.000656   0.011166  0.002386  0.011194  0.003384    0.153691  0.034821   \n",
       "5  0.000023   0.151924  0.003713  0.001086  0.004907    0.570237  0.000352   \n",
       "6  0.000030   0.061414  0.054991  0.000012  0.000174    0.845745  0.038545   \n",
       "7  0.000023   0.003859  0.168180  0.000784  0.002018    0.260326  0.002429   \n",
       "\n",
       "   p_Western  \n",
       "1   0.002179  \n",
       "4   0.003528  \n",
       "5   0.000962  \n",
       "6   0.000065  \n",
       "7   0.001002  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)\n",
    "res.to_csv('pred_genres_text_RF.csv', index_label='ID')\n",
    "res.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
